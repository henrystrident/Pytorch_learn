{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前言\n",
    "pytorch的使用方法，第一章学习的是pytorch中向量的输入，如何将普通数组转化为pytorch中的规定格式的数组。最后实现以下线性规划"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看pytorch版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch中的向量（Tensor）及其生成方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.随机生成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9465, 0.3782, 0.7209, 0.2407, 0.0663],\n",
      "        [0.0568, 0.3566, 0.6090, 0.6453, 0.0935],\n",
      "        [0.1504, 0.4756, 0.9978, 0.7952, 0.0228]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,5)\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.生成全0和全1的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zero_tensor = torch.zeros(3,5)\n",
    "print(zero_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ones_tensor = torch.ones(3,5)\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.根据数据直接创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "list = [[1,2,3],\n",
    "        [4,5,6]]\n",
    "tensor = torch.tensor(list)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Numpy和torch的互相转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.array(list)\n",
    "tensor = torch.from_numpy(array).float()\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "array = tensor.numpy()\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：tensor转成numpy时，两个向量共用内存，一个改变另一个也会改变；numpy转成tensor时使用的时拷贝，不会同时改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写一个线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.如何反向传播和求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的神经网络都需要进行梯度的反向传播和求导，在纸上很容易实现，但是在代码上体现并不容易，如果我们想要进行求导这个操作，可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y关于x的导数是：tensor([1.])，y进行的操作是：<AddBackward0 object at 0x0000021F774D6C50>\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.],requires_grad=True)\n",
    "y = x+2\n",
    "y.backward()\n",
    "print('y关于x的导数是：{}，y进行的操作是：{}'.format(x.grad, y.grad_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，在变量声明时我们需要告诉计算机，这个变量是需要进行梯度追踪的：requires_grad=True。其次需要让因变量进行反向传播：y.backward()。最终，通过变量.grad()求出导数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.生成数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先生成50个[0,100]内的随机数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "x = []\n",
    "for i in range(50):\n",
    "    x.append(round(random.uniform(0,100), 2))\n",
    "Train_data_x = torch.tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真实的直线设定为y=2*x+3，根据这条直线再随机加上一些偏差，模拟数据集，并用matploit展示出来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "true_weight, true_bias = 2, 3\n",
    "label = Train_data_x * true_weight + true_bias\n",
    "label += torch.tensor(10*np.random.random(50)+3)\n",
    "plt.scatter(Train_data_x, label, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了torch.tensor类型的输入（Train_data_x）和标签(label)后，我们还需把他们转换成模型能读入的数据类型DalaLoader："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.9600, 43.2000, 34.3900, 39.9400, 91.3700, 64.8800, 32.5000, 66.9600,\n",
      "         7.3800, 87.8500]) \n",
      " tensor([ 29.9891, 101.3768,  77.6998,  94.2723, 197.4821, 143.0810,  77.5085,\n",
      "        148.4566,  24.6664, 183.2752])\n",
      "tensor([84.9000,  2.5700, 14.7000, 38.8000, 59.0800, 40.0800, 54.5700, 95.5600,\n",
      "        95.8900, 18.3900]) \n",
      " tensor([184.9252,  12.6410,  39.5457,  85.4456, 128.5162,  87.1056, 116.9533,\n",
      "        205.0364, 198.0064,  49.7109])\n",
      "tensor([ 0.4500, 19.7400, 81.3700, 87.4800,  7.3600, 49.2400, 91.6100, 67.8300,\n",
      "        30.7500, 41.5100]) \n",
      " tensor([ 13.1555,  49.4515, 175.4591, 181.5543,  26.9325, 111.0981, 190.4976,\n",
      "        147.0613,  77.2011,  98.6023])\n",
      "tensor([80.4000, 59.6900, 79.5500, 47.6200, 11.7500, 73.2400, 61.0200, 34.9000,\n",
      "        23.6500, 36.1400]) \n",
      " tensor([175.1518, 130.7014, 171.0392, 104.3937,  29.5268, 153.6101, 136.6791,\n",
      "         80.0104,  58.6555,  87.7758])\n",
      "tensor([ 2.9600,  7.5300, 66.4400, 26.7000, 80.1400, 96.0600, 59.3600,  3.3600,\n",
      "        82.5900, 24.5200]) \n",
      " tensor([ 18.6455,  26.1304, 140.3654,  60.1712, 168.5316, 203.4555, 132.3127,\n",
      "         22.1551, 176.0180,  57.7512])\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "dataset = Data.TensorDataset(Train_data_x, label)\n",
    "dataiter = Data.DataLoader(dataset=dataset,\n",
    "                           batch_size=10,\n",
    "                           shuffle=True,)\n",
    "for x, y in dataiter:\n",
    "    print(x, '\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.定义自己的网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义网络通过torch.nn实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.7037]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6549], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(n_feature, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "linear_net = LinearNet(1)\n",
    "print(linear_net.linear.weight)\n",
    "print(linear_net.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.定义损失函数及优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数用均方误差，优化方法用随机梯度下降："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.SGD(linear_net.parameters(), lr=0.00003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, loss:1226.679443359375\n",
      "epoch2, loss:156.35964965820312\n",
      "epoch3, loss:49.32404327392578\n",
      "epoch4, loss:61.44105911254883\n",
      "epoch5, loss:35.276912689208984\n",
      "epoch6, loss:49.68880081176758\n",
      "epoch7, loss:31.92144775390625\n",
      "epoch8, loss:37.58811950683594\n",
      "epoch9, loss:31.979211807250977\n",
      "epoch10, loss:33.45459747314453\n",
      "epoch11, loss:33.64426803588867\n",
      "epoch12, loss:23.567359924316406\n",
      "epoch13, loss:30.947345733642578\n",
      "epoch14, loss:66.07997131347656\n",
      "epoch15, loss:48.456871032714844\n",
      "epoch16, loss:55.4990234375\n",
      "epoch17, loss:25.984577178955078\n",
      "epoch18, loss:56.57416534423828\n",
      "epoch19, loss:45.68144989013672\n",
      "epoch20, loss:35.94047164916992\n",
      "epoch21, loss:49.1015625\n",
      "epoch22, loss:23.511816024780273\n",
      "epoch23, loss:53.051963806152344\n",
      "epoch24, loss:91.90177154541016\n",
      "epoch25, loss:64.89215087890625\n",
      "epoch26, loss:46.8785400390625\n",
      "epoch27, loss:65.24182891845703\n",
      "epoch28, loss:27.638891220092773\n",
      "epoch29, loss:22.36319351196289\n",
      "epoch30, loss:69.99288940429688\n",
      "epoch31, loss:43.51637268066406\n",
      "epoch32, loss:45.49732971191406\n",
      "epoch33, loss:38.034217834472656\n",
      "epoch34, loss:41.756675720214844\n",
      "epoch35, loss:32.37773895263672\n",
      "epoch36, loss:44.249732971191406\n",
      "epoch37, loss:51.75566482543945\n",
      "epoch38, loss:28.279891967773438\n",
      "epoch39, loss:29.787677764892578\n",
      "epoch40, loss:63.5820198059082\n",
      "epoch41, loss:60.962791442871094\n",
      "epoch42, loss:68.0135269165039\n",
      "epoch43, loss:55.39470672607422\n",
      "epoch44, loss:70.2119140625\n",
      "epoch45, loss:55.618263244628906\n",
      "epoch46, loss:30.158340454101562\n",
      "epoch47, loss:32.90534210205078\n",
      "epoch48, loss:60.20615768432617\n",
      "epoch49, loss:58.454505920410156\n",
      "epoch50, loss:67.89179992675781\n",
      "epoch51, loss:49.0363883972168\n",
      "epoch52, loss:52.19520950317383\n",
      "epoch53, loss:55.64522171020508\n",
      "epoch54, loss:81.1318359375\n",
      "epoch55, loss:54.33747482299805\n",
      "epoch56, loss:42.52503204345703\n",
      "epoch57, loss:45.80950164794922\n",
      "epoch58, loss:43.004127502441406\n",
      "epoch59, loss:45.83208465576172\n",
      "epoch60, loss:25.864185333251953\n",
      "epoch61, loss:42.21942138671875\n",
      "epoch62, loss:38.498046875\n",
      "epoch63, loss:46.41193771362305\n",
      "epoch64, loss:71.18397521972656\n",
      "epoch65, loss:70.91951751708984\n",
      "epoch66, loss:61.96559524536133\n",
      "epoch67, loss:35.047019958496094\n",
      "epoch68, loss:62.23299026489258\n",
      "epoch69, loss:26.560138702392578\n",
      "epoch70, loss:68.87805938720703\n",
      "epoch71, loss:65.4384536743164\n",
      "epoch72, loss:46.337791442871094\n",
      "epoch73, loss:73.29252624511719\n",
      "epoch74, loss:29.236114501953125\n",
      "epoch75, loss:74.15379333496094\n",
      "epoch76, loss:37.138885498046875\n",
      "epoch77, loss:42.570899963378906\n",
      "epoch78, loss:83.23355865478516\n",
      "epoch79, loss:59.745460510253906\n",
      "epoch80, loss:44.377708435058594\n",
      "epoch81, loss:42.264923095703125\n",
      "epoch82, loss:45.60871124267578\n",
      "epoch83, loss:39.844520568847656\n",
      "epoch84, loss:26.46062660217285\n",
      "epoch85, loss:30.83670425415039\n",
      "epoch86, loss:28.000015258789062\n",
      "epoch87, loss:38.63774871826172\n",
      "epoch88, loss:33.5980339050293\n",
      "epoch89, loss:59.0872802734375\n",
      "epoch90, loss:48.822044372558594\n",
      "epoch91, loss:15.169660568237305\n",
      "epoch92, loss:54.91112518310547\n",
      "epoch93, loss:69.22380065917969\n",
      "epoch94, loss:43.36426544189453\n",
      "epoch95, loss:34.341697692871094\n",
      "epoch96, loss:36.72136688232422\n",
      "epoch97, loss:28.1162166595459\n",
      "epoch98, loss:34.35126876831055\n",
      "epoch99, loss:76.5392074584961\n",
      "epoch100, loss:55.77052688598633\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for input, ground_truth in dataiter:\n",
    "        output = linear_net(input.view(10, -1))\n",
    "        l = loss(output, ground_truth.view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch{}, loss:{}'.format(i+1, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.1709]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.5341], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(linear_net.linear.weight, linear_net.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight还行，但是bias不太好，不知道为什么"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
